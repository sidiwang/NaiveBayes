---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# NaiveBayes

<!-- badges: start -->
  [![Travis build status](https://travis-ci.org/sidiwang/NaiveBayes.svg?branch=master)](https://travis-ci.org/sidiwang/NaiveBayes)
  <!-- badges: end -->


<!-- badges: start -->
  [![Codecov test coverage](https://codecov.io/gh/sidiwang/NaiveBayes/branch/master/graph/badge.svg)](https://codecov.io/gh/sidiwang/NaiveBayes?branch=master)
  <!-- badges: end -->

This is a homework assignment of BIOSTAT625 at the Univeristy of Michigan, Ann Arbor.

The **NaiveBayes** package provides an efficient implementation of the popular Naive Bayes classifier. This package is efficient, user friendly and written in <span style = "color:purple">base.R and Rcpp</span>. Like many other classifier packages, the *general* function **NaiveBayes** detects the class of each feature in the dataset. *Predict* function uses a NaiveBayes model and a new data set to create the classifications. This can either be the **raw** probabilities generated by the NaiveBayes model or the **classes** themselves.

## Installation

You can download and install <span style = "color:purple">NaiveBayes</span> with:

``` {r}
library(devtools)
devtools::install_github("sidiwang/NaiveBayes", build_vignettes = T)
library(NaiveBayes)
```

The vignettes of this package contains very detailed infomation on <span style = "color:purple">"What is Naive Bayes", "How to implement Naive Bayes", "The pros and cons of Naive Bayes"</span> and how numerical underflow is handled during calculation. Various examples on how to use this package, and a **performance comparison** against the *naiveBayes* function in package **e1071** were also included. Given the <span style = "color:purple">NaiveBayes</span> function was partially written in Rcpp and vectorized some calculations in matrix form, our performance, in general, is better in efficiency and need less memory allocation.

Please use this code to check the vignettes.

```{r}
browseVignettes("NaiveBayes")
```

## Example

This is a basic example which shows you how to solve a common problem:

```{r example}
library(NaiveBayes)
## load data, and define X and Y
data("HouseVotes84")
x = HouseVotes84[, -c(1,9:17)]
y = HouseVotes84[, 1]

# fit the model
mymodel = NaiveBayes::NaiveBayes(x, y)
# check output
mymodel
```

```{r}
# prediction, here we predicted on the original training dataset for simplicity purpose, but you can always feed new dataset into the function.
prediction = predict(mymodel, x)
# check first 10 predictions
prediction[1:10]

```

## Limitations and reminders:

+ We are currently assuming Gaussian distribution for continuous variables, which is the typical assumption. In reality this may not always be the most appropriate choice. More distribution options can be easily added into the package, and will be added in the future.
+ Please correctly specify the data type of each column in your dataset before feeding it into the <span style = "color:purple">NaiveBayes</span> function. As continuous variables and categorical variables should be treated differently according to the algorithm.
+ This is the **very first Rcpp / C++ program** written by the author, unaware of many Rcpp / C++ functions and coding rules,  many redundant code may be included. Better efficiencies should be achieved in the future as the author become more experienced in coding Rcpp / C++.



